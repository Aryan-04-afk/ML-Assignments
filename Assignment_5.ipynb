{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpIKth8FnFNp",
        "outputId": "52e9a3ff-ab0e-4fd2-8ce3-fc899e2770c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4156739715.py:39: RuntimeWarning: invalid value encountered in multiply\n",
            "  grad[1:] += (lam/n) * w[1:]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters:\n",
            "Learning Rate    1.000000e-01\n",
            "Lambda           1.000000e-15\n",
            "Cost             2.440112e-03\n",
            "R2_Score         9.466391e-01\n",
            "Name: 24, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "n_samples = 200\n",
        "X1 = np.random.rand(n_samples)\n",
        "X2 = X1 + np.random.normal(0, 0.01, n_samples)\n",
        "X3 = 2 * X1 + np.random.normal(0, 0.02, n_samples)\n",
        "X4 = 3 * X1 + np.random.normal(0, 0.03, n_samples)\n",
        "X5 = 0.5 * X1 + np.random.normal(0, 0.01, n_samples)\n",
        "X6 = X1 + X2 + np.random.normal(0, 0.02, n_samples)\n",
        "X7 = X3 - X5 + np.random.normal(0, 0.02, n_samples)\n",
        "\n",
        "X = np.column_stack((X1, X2, X3, X4, X5, X6, X7))\n",
        "\n",
        "y = 5*X1 + 2*X2 - 3*X3 + np.random.normal(0, 0.05, n_samples)\n",
        "\n",
        "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "\n",
        "X = np.c_[np.ones(n_samples), X]\n",
        "\n",
        "def ridge_cost(X, y, w, lam):\n",
        "    n = len(y)\n",
        "    y_pred = X.dot(w)\n",
        "    cost = (1/(2*n)) * np.sum((y_pred - y)**2) + (lam/(2*n)) * np.sum(w[1:]**2)\n",
        "    return cost\n",
        "\n",
        "def ridge_gradient(X, y, w, lam):\n",
        "    n = len(y)\n",
        "    y_pred = X.dot(w)\n",
        "    grad = (1/n) * X.T.dot(y_pred - y)\n",
        "    grad[1:] += (lam/n) * w[1:]\n",
        "    return grad\n",
        "\n",
        "def gradient_descent(X, y, lr, lam, epochs=1000):\n",
        "    w = np.zeros(X.shape[1])\n",
        "    for _ in range(epochs):\n",
        "        grad = ridge_gradient(X, y, w, lam)\n",
        "        w -= lr * grad\n",
        "    return w\n",
        "\n",
        "def r2_score(y_true, y_pred):\n",
        "    ss_res = np.sum((y_true - y_pred)**2)\n",
        "    ss_tot = np.sum((y_true - np.mean(y_true))**2)\n",
        "    return 1 - (ss_res / ss_tot)\n",
        "\n",
        "learning_rates = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
        "lambdas = [1e-15, 1e-10, 1e-5, 1e-3, 0, 1, 10, 20]\n",
        "\n",
        "results = []\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for lam in lambdas:\n",
        "        w = gradient_descent(X, y, lr, lam, epochs=2000)\n",
        "        cost = ridge_cost(X, y, w, lam)\n",
        "        y_pred = X.dot(w)\n",
        "        r2 = r2_score(y, y_pred)\n",
        "        results.append((lr, lam, cost, r2))\n",
        "\n",
        "df_results = pd.DataFrame(results, columns=['Learning Rate', 'Lambda', 'Cost', 'R2_Score'])\n",
        "best = df_results.loc[df_results['R2_Score'].idxmax()]\n",
        "\n",
        "print(\"Best Parameters:\")\n",
        "print(best)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "import gdown\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "url = \"https://drive.google.com/uc?id=1qzCKF6JKKMB0p7ul_lLy8tdmRk3vE_bG\"\n",
        "output = \"Hitters.csv\"\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "df = pd.read_csv(output)\n",
        "\n",
        "df = df.dropna(subset=['Salary'])\n",
        "df = pd.get_dummies(df, columns=['League', 'Division', 'NewLeague'], drop_first=True)\n",
        "\n",
        "y = df['Salary']\n",
        "X = df.drop(['Salary', 'Name'], axis=1, errors='ignore')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train_scaled, y_train)\n",
        "y_pred_lin = lin_reg.predict(X_test_scaled)\n",
        "\n",
        "ridge_reg = Ridge(alpha=0.5748)\n",
        "ridge_reg.fit(X_train_scaled, y_train)\n",
        "y_pred_ridge = ridge_reg.predict(X_test_scaled)\n",
        "\n",
        "lasso_reg = Lasso(alpha=0.5748, max_iter=10000)\n",
        "lasso_reg.fit(X_train_scaled, y_train)\n",
        "y_pred_lasso = lasso_reg.predict(X_test_scaled)\n",
        "\n",
        "results = {}\n",
        "for name, y_pred in [('Linear', y_pred_lin), ('Ridge', y_pred_ridge), ('Lasso', y_pred_lasso)]:\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    results[name] = {'MSE': mse, 'R2': r2}\n",
        "    print(f\"{name} Regression → MSE: {mse:.2f}, R2: {r2:.4f}\")\n",
        "\n",
        "best_model = max(results, key=lambda m: results[m]['R2'])\n",
        "print(\"\\nBest Model:\", best_model)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "id": "pF7bgNv_nbr9",
        "outputId": "507d8ff4-eb3b-41d9-fc94-f3f3f24f2fe9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.20.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.10.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileURLRetrievalError",
          "evalue": "Failed to retrieve file url:\n\n\tCannot retrieve the public link of the file. You may need to change\n\tthe permission to 'Anyone with the link', or have had many accesses.\n\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=1qzCKF6JKKMB0p7ul_lLy8tdmRk3vE_bG\n\nbut Gdown can't. Please check connections and permissions.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_url_from_gdrive_confirmation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mget_url_from_gdrive_confirmation\u001b[0;34m(contents)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         raise FileURLRetrievalError(\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0;34m\"Cannot retrieve the public link of the file. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m: Cannot retrieve the public link of the file. You may need to change the permission to 'Anyone with the link', or have had many accesses. Check FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3959418731.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://drive.google.com/uc?id=1qzCKF6JKKMB0p7ul_lLy8tdmRk3vE_bG\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Hitters.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0murl_origin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             )\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mfilename_from_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m: Failed to retrieve file url:\n\n\tCannot retrieve the public link of the file. You may need to change\n\tthe permission to 'Anyone with the link', or have had many accesses.\n\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=1qzCKF6JKKMB0p7ul_lLy8tdmRk3vE_bG\n\nbut Gdown can't. Please check connections and permissions."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import RidgeCV, LassoCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "boston = fetch_openml(name='boston', version=1, as_frame=True)\n",
        "X = boston.data\n",
        "y = boston.target\n",
        "\n",
        "print(\"Dataset loaded successfully!\")\n",
        "print(X.head())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "alphas = np.logspace(-3, 3, 50)\n",
        "ridge_cv = RidgeCV(alphas=alphas, scoring='r2', cv=5)\n",
        "ridge_cv.fit(X_train_scaled, y_train)\n",
        "\n",
        "ridge_best_alpha = ridge_cv.alpha_\n",
        "y_pred_ridge = ridge_cv.predict(X_test_scaled)\n",
        "ridge_mse = mean_squared_error(y_test, y_pred_ridge)\n",
        "ridge_r2 = r2_score(y_test, y_pred_ridge)\n",
        "\n",
        "print(\"\\n=== Ridge Regression CV Results ===\")\n",
        "print(\"Best alpha:\", ridge_best_alpha)\n",
        "print(f\"MSE: {ridge_mse:.3f}\")\n",
        "print(f\"R²: {ridge_r2:.3f}\")\n",
        "\n",
        "\n",
        "lasso_cv = LassoCV(alphas=alphas, cv=5, max_iter=10000)\n",
        "lasso_cv.fit(X_train_scaled, y_train)\n",
        "\n",
        "lasso_best_alpha = lasso_cv.alpha_\n",
        "y_pred_lasso = lasso_cv.predict(X_test_scaled)\n",
        "lasso_mse = mean_squared_error(y_test, y_pred_lasso)\n",
        "lasso_r2 = r2_score(y_test, y_pred_lasso)\n",
        "\n",
        "print(\"\\n=== Lasso Regression CV Results ===\")\n",
        "print(\"Best alpha:\", lasso_best_alpha)\n",
        "print(f\"MSE: {lasso_mse:.3f}\")\n",
        "print(f\"R²: {lasso_r2:.3f}\")\n",
        "\n",
        "\n",
        "print(\"\\n=== Comparison ===\")\n",
        "print(f\"Ridge R²: {ridge_r2:.3f}, Lasso R²: {lasso_r2:.3f}\")\n",
        "print(f\"Ridge MSE: {ridge_mse:.3f}, Lasso MSE: {lasso_mse:.3f}\")\n",
        "\n",
        "if ridge_r2 > lasso_r2:\n",
        "    print(\"Best Model: Ridge Regression (better generalization and stability)\")\n",
        "else:\n",
        "    print(\"Best Model: Lasso Regression (more sparse feature selection)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qM8xsTsny4l",
        "outputId": "7a45d7c8-0915-4c5a-de16-af97b366826a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully!\n",
            "      CRIM    ZN  INDUS CHAS    NOX     RM   AGE     DIS RAD    TAX  PTRATIO  \\\n",
            "0  0.00632  18.0   2.31    0  0.538  6.575  65.2  4.0900   1  296.0     15.3   \n",
            "1  0.02731   0.0   7.07    0  0.469  6.421  78.9  4.9671   2  242.0     17.8   \n",
            "2  0.02729   0.0   7.07    0  0.469  7.185  61.1  4.9671   2  242.0     17.8   \n",
            "3  0.03237   0.0   2.18    0  0.458  6.998  45.8  6.0622   3  222.0     18.7   \n",
            "4  0.06905   0.0   2.18    0  0.458  7.147  54.2  6.0622   3  222.0     18.7   \n",
            "\n",
            "        B  LSTAT  \n",
            "0  396.90   4.98  \n",
            "1  396.90   9.14  \n",
            "2  392.83   4.03  \n",
            "3  394.63   2.94  \n",
            "4  396.90   5.33  \n",
            "\n",
            "=== Ridge Regression CV Results ===\n",
            "Best alpha: 2.6826957952797246\n",
            "MSE: 24.349\n",
            "R²: 0.668\n",
            "\n",
            "=== Lasso Regression CV Results ===\n",
            "Best alpha: 0.001\n",
            "MSE: 24.295\n",
            "R²: 0.669\n",
            "\n",
            "=== Comparison ===\n",
            "Ridge R²: 0.668, Lasso R²: 0.669\n",
            "Ridge MSE: 24.349, Lasso MSE: 24.295\n",
            "Best Model: Lasso Regression (more sparse feature selection)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "print(\"Classes:\", iris.target_names)\n",
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of y:\", y.shape)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def compute_cost(X, y, weights):\n",
        "    n = len(y)\n",
        "    h = sigmoid(X.dot(weights))\n",
        "    return -(1/n) * (np.sum(y*np.log(h + 1e-15) + (1-y)*np.log(1-h + 1e-15)))\n",
        "\n",
        "def gradient_descent(X, y, lr=0.1, epochs=1000):\n",
        "    n, m = X.shape\n",
        "    weights = np.zeros(m)\n",
        "    for _ in range(epochs):\n",
        "        h = sigmoid(X.dot(weights))\n",
        "        gradient = (1/n) * X.T.dot(h - y)\n",
        "        weights -= lr * gradient\n",
        "    return weights\n",
        "\n",
        "\n",
        "def train_one_vs_rest(X, y, lr=0.1, epochs=2000):\n",
        "    classes = np.unique(y)\n",
        "    all_weights = []\n",
        "    for c in classes:\n",
        "\n",
        "        y_binary = np.where(y == c, 1, 0)\n",
        "        w = gradient_descent(X, y_binary, lr, epochs)\n",
        "        all_weights.append(w)\n",
        "    return np.array(all_weights)\n",
        "\n",
        "X_train_bias = np.c_[np.ones(X_train.shape[0]), X_train]\n",
        "X_test_bias = np.c_[np.ones(X_test.shape[0]), X_test]\n",
        "\n",
        "weights = train_one_vs_rest(X_train_bias, y_train, lr=0.1, epochs=2000)\n",
        "\n",
        "\n",
        "def predict_one_vs_rest(X, weights):\n",
        "    probs = sigmoid(X.dot(weights.T))\n",
        "    return np.argmax(probs, axis=1)\n",
        "\n",
        "y_pred = predict_one_vs_rest(X_test_bias, weights)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Predicted labels:\", y_pred)\n",
        "print(\"True labels:\", y_test)\n",
        "print(f\"\\nModel Accuracy: {accuracy*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21k1TGVOoZC7",
        "outputId": "12bbb7d3-830a-498c-9298-e47eadb458b6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['setosa' 'versicolor' 'virginica']\n",
            "Shape of X: (150, 4)\n",
            "Shape of y: (150,)\n",
            "Predicted labels: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 2 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n",
            "True labels: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n",
            "\n",
            "Model Accuracy: 96.67%\n"
          ]
        }
      ]
    }
  ]
}